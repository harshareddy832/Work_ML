{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.6.0-cp38-cp38-win_amd64.whl (423.2 MB)\n",
      "Collecting protobuf>=3.9.2\n",
      "  Downloading protobuf-3.17.3-cp38-cp38-win_amd64.whl (909 kB)\n",
      "Collecting gast==0.4.0\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\users\\pasha\\anaconda3\\lib\\site-packages (from tensorflow) (3.7.4.3)\n",
      "Collecting astunparse~=1.6.3\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting h5py~=3.1.0\n",
      "  Downloading h5py-3.1.0-cp38-cp38-win_amd64.whl (2.7 MB)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\pasha\\anaconda3\\lib\\site-packages (from tensorflow) (0.35.1)\n",
      "Collecting keras-preprocessing~=1.1.2\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting google-pasta~=0.2\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting keras~=2.6\n",
      "  Downloading keras-2.6.0-py2.py3-none-any.whl (1.3 MB)\n",
      "Collecting absl-py~=0.10\n",
      "  Using cached absl_py-0.13.0-py3-none-any.whl (132 kB)\n",
      "Collecting termcolor~=1.1.0\n",
      "  Using cached termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting flatbuffers~=1.12.0\n",
      "  Using cached flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting wrapt~=1.12.1\n",
      "  Using cached wrapt-1.12.1.tar.gz (27 kB)\n",
      "Collecting opt-einsum~=3.3.0\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: six~=1.15.0 in c:\\users\\pasha\\anaconda3\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Collecting clang~=5.0\n",
      "  Downloading clang-5.0.tar.gz (30 kB)\n",
      "Collecting grpcio<2.0,>=1.37.0\n",
      "  Downloading grpcio-1.40.0-cp38-cp38-win_amd64.whl (3.2 MB)\n",
      "Collecting tensorflow-estimator~=2.6\n",
      "  Downloading tensorflow_estimator-2.6.0-py2.py3-none-any.whl (462 kB)\n",
      "Collecting tensorboard~=2.6\n",
      "  Using cached tensorboard-2.6.0-py3-none-any.whl (5.6 MB)\n",
      "Requirement already satisfied: numpy~=1.19.2 in c:\\users\\pasha\\anaconda3\\lib\\site-packages (from tensorflow) (1.19.2)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.35.0-py2.py3-none-any.whl (152 kB)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\pasha\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (50.3.1.post20201107)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\pasha\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\pasha\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.24.0)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\pasha\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (1.0.1)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Using cached cachetools-4.2.2-py3-none-any.whl (11 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting rsa<5,>=3.1.4; python_version >= \"3.6\"\n",
      "  Using cached rsa-4.7.2-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pasha\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\pasha\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\pasha\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\pasha\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.25.11)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\n",
      "Building wheels for collected packages: termcolor, wrapt, clang\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4835 sha256=ca8ae4d73f6ff36d09cf3da6ba66b145e1b423a9a036119ba5357c0f6c847572\n",
      "  Stored in directory: c:\\users\\pasha\\appdata\\local\\pip\\cache\\wheels\\a0\\16\\9c\\5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n",
      "  Building wheel for wrapt (setup.py): started\n",
      "  Building wheel for wrapt (setup.py): finished with status 'done'\n",
      "  Created wheel for wrapt: filename=wrapt-1.12.1-py3-none-any.whl size=19558 sha256=c42380ff0b12f1ad048cc07e2a5e50051f931bf65d64969930b2a782a337da9f\n",
      "  Stored in directory: c:\\users\\pasha\\appdata\\local\\pip\\cache\\wheels\\5f\\fd\\9e\\b6cf5890494cb8ef0b5eaff72e5d55a70fb56316007d6dfe73\n",
      "  Building wheel for clang (setup.py): started\n",
      "  Building wheel for clang (setup.py): finished with status 'done'\n",
      "  Created wheel for clang: filename=clang-5.0-py3-none-any.whl size=30710 sha256=40a635920361dfc0531c02843c816a99ad1ae777acb668a26a1411830f868cdf\n",
      "  Stored in directory: c:\\users\\pasha\\appdata\\local\\pip\\cache\\wheels\\f1\\60\\77\\22b9b5887bd47801796a856f47650d9789c74dc3161a26d608\n",
      "Successfully built termcolor wrapt clang\n",
      "Installing collected packages: protobuf, gast, astunparse, h5py, keras-preprocessing, google-pasta, keras, absl-py, termcolor, flatbuffers, wrapt, opt-einsum, clang, grpcio, tensorflow-estimator, cachetools, pyasn1, pyasn1-modules, rsa, google-auth, tensorboard-data-server, tensorboard-plugin-wit, oauthlib, requests-oauthlib, google-auth-oauthlib, tensorboard, tensorflow\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 2.10.0\n",
      "    Uninstalling h5py-2.10.0:\n",
      "      Successfully uninstalled h5py-2.10.0\n",
      "  Attempting uninstall: wrapt\n",
      "    Found existing installation: wrapt 1.11.2\n",
      "    Uninstalling wrapt-1.11.2:\n",
      "      Successfully uninstalled wrapt-1.11.2\n",
      "Successfully installed absl-py-0.13.0 astunparse-1.6.3 cachetools-4.2.2 clang-5.0 flatbuffers-1.12 gast-0.4.0 google-auth-1.35.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.40.0 h5py-3.1.0 keras-2.6.0 keras-preprocessing-1.1.2 oauthlib-3.1.1 opt-einsum-3.3.0 protobuf-3.17.3 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rsa-4.7.2 tensorboard-2.6.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.0 tensorflow-2.6.0 tensorflow-estimator-2.6.0 termcolor-1.1.0 wrapt-1.12.1\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist=tf.keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 1us/step\n",
      "40960/29515 [=========================================] - 0s 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 8s 0us/step\n",
      "26435584/26421880 [==============================] - 8s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "16384/5148 [===============================================================================================] - 0s 0s/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 2s 0us/step\n",
      "4431872/4422102 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(training_images,training_labels),(test_images,test_labels)=mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   1   0   0  13  73   0   0   1   4   0   0   0   0   1   1   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  36 136 127  62  54   0   0   0   1   3   4   0   0   3]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   6   0 102 204 176 134 144 123  23   0   0   0   0  12  10   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 155 236 207 178 107 156 161 109  64  23  77 130  72  15]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   1   0  69 207 223 218 216 216 163 127 121 122 146 141  88 172  66]\n",
      " [  0   0   0   0   0   0   0   0   0   1   1   1   0 200 232 232 233 229 223 223 215 213 164 127 123 196 229   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 183 225 216 223 228 235 227 224 222 224 221 223 245 173   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 193 228 218 213 198 180 212 210 211 213 223 220 243 202   0]\n",
      " [  0   0   0   0   0   0   0   0   0   1   3   0  12 219 220 212 218 192 169 227 208 218 224 212 226 197 209  52]\n",
      " [  0   0   0   0   0   0   0   0   0   0   6   0  99 244 222 220 218 203 198 221 215 213 222 220 245 119 167  56]\n",
      " [  0   0   0   0   0   0   0   0   0   4   0   0  55 236 228 230 228 240 232 213 218 223 234 217 217 209  92   0]\n",
      " [  0   0   1   4   6   7   2   0   0   0   0   0 237 226 217 223 222 219 222 221 216 223 229 215 218 255  77   0]\n",
      " [  0   3   0   0   0   0   0   0   0  62 145 204 228 207 213 221 218 208 211 218 224 223 219 215 224 244 159   0]\n",
      " [  0   0   0   0  18  44  82 107 189 228 220 222 217 226 200 205 211 230 224 234 176 188 250 248 233 238 215   0]\n",
      " [  0  57 187 208 224 221 224 208 204 214 208 209 200 159 245 193 206 223 255 255 221 234 221 211 220 232 246   0]\n",
      " [  3 202 228 224 221 211 211 214 205 205 205 220 240  80 150 255 229 221 188 154 191 210 204 209 222 228 225   0]\n",
      " [ 98 233 198 210 222 229 229 234 249 220 194 215 217 241  65  73 106 117 168 219 221 215 217 223 223 224 229  29]\n",
      " [ 75 204 212 204 193 205 211 225 216 185 197 206 198 213 240 195 227 245 239 223 218 212 209 222 220 221 230  67]\n",
      " [ 48 203 183 194 213 197 185 190 194 192 202 214 219 221 220 236 225 216 199 206 186 181 177 172 181 205 206 115]\n",
      " [  0 122 219 193 179 171 183 196 204 210 213 207 211 210 200 196 194 191 195 191 198 192 176 156 167 177 210  92]\n",
      " [  0   0  74 189 212 191 175 172 175 181 185 188 189 188 193 198 204 209 210 210 211 188 188 194 192 216 170   0]\n",
      " [  2   0   0   0  66 200 222 237 239 242 246 243 244 221 220 193 191 179 182 182 181 176 166 168  99  58   0   0]\n",
      " [  0   0   0   0   0   0   0  40  61  44  72  41  35   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
      "9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "np.set_printoptions(linewidth=300)\n",
    "plt.imshow(training_images[0])\n",
    "print(training_images[0])\n",
    "print(training_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images=training_images/255.0\n",
    "test_images=test_images/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
      "  0.        ]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
      "  0.        ]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
      "  0.        ]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.00392157 0.         0.         0.05098039 0.28627451 0.         0.         0.00392157 0.01568627 0.         0.         0.         0.         0.00392157 0.00392157\n",
      "  0.        ]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.01176471 0.         0.14117647 0.53333333 0.49803922 0.24313725 0.21176471 0.         0.         0.         0.00392157 0.01176471 0.01568627 0.         0.\n",
      "  0.01176471]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.02352941 0.         0.4        0.8        0.69019608 0.5254902  0.56470588 0.48235294 0.09019608 0.         0.         0.         0.         0.04705882 0.03921569\n",
      "  0.        ]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.60784314 0.9254902  0.81176471 0.69803922 0.41960784 0.61176471 0.63137255 0.42745098 0.25098039 0.09019608 0.30196078 0.50980392 0.28235294\n",
      "  0.05882353]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.00392157 0.         0.27058824 0.81176471 0.8745098  0.85490196 0.84705882 0.84705882 0.63921569 0.49803922 0.4745098  0.47843137 0.57254902 0.55294118 0.34509804 0.6745098\n",
      "  0.25882353]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.00392157 0.00392157 0.00392157 0.         0.78431373 0.90980392 0.90980392 0.91372549 0.89803922 0.8745098  0.8745098  0.84313725 0.83529412 0.64313725 0.49803922 0.48235294 0.76862745 0.89803922\n",
      "  0.        ]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.71764706 0.88235294 0.84705882 0.8745098  0.89411765 0.92156863 0.89019608 0.87843137 0.87058824 0.87843137 0.86666667 0.8745098  0.96078431 0.67843137\n",
      "  0.        ]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.75686275 0.89411765 0.85490196 0.83529412 0.77647059 0.70588235 0.83137255 0.82352941 0.82745098 0.83529412 0.8745098  0.8627451  0.95294118 0.79215686\n",
      "  0.        ]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.00392157 0.01176471 0.         0.04705882 0.85882353 0.8627451  0.83137255 0.85490196 0.75294118 0.6627451  0.89019608 0.81568627 0.85490196 0.87843137 0.83137255 0.88627451 0.77254902 0.81960784\n",
      "  0.20392157]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.02352941 0.         0.38823529 0.95686275 0.87058824 0.8627451  0.85490196 0.79607843 0.77647059 0.86666667 0.84313725 0.83529412 0.87058824 0.8627451  0.96078431 0.46666667 0.65490196\n",
      "  0.21960784]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.01568627 0.         0.         0.21568627 0.9254902  0.89411765 0.90196078 0.89411765 0.94117647 0.90980392 0.83529412 0.85490196 0.8745098  0.91764706 0.85098039 0.85098039 0.81960784 0.36078431\n",
      "  0.        ]\n",
      " [0.         0.         0.00392157 0.01568627 0.02352941 0.02745098 0.00784314 0.         0.         0.         0.         0.         0.92941176 0.88627451 0.85098039 0.8745098  0.87058824 0.85882353 0.87058824 0.86666667 0.84705882 0.8745098  0.89803922 0.84313725 0.85490196 1.         0.30196078\n",
      "  0.        ]\n",
      " [0.         0.01176471 0.         0.         0.         0.         0.         0.         0.         0.24313725 0.56862745 0.8        0.89411765 0.81176471 0.83529412 0.86666667 0.85490196 0.81568627 0.82745098 0.85490196 0.87843137 0.8745098  0.85882353 0.84313725 0.87843137 0.95686275 0.62352941\n",
      "  0.        ]\n",
      " [0.         0.         0.         0.         0.07058824 0.17254902 0.32156863 0.41960784 0.74117647 0.89411765 0.8627451  0.87058824 0.85098039 0.88627451 0.78431373 0.80392157 0.82745098 0.90196078 0.87843137 0.91764706 0.69019608 0.7372549  0.98039216 0.97254902 0.91372549 0.93333333 0.84313725\n",
      "  0.        ]\n",
      " [0.         0.22352941 0.73333333 0.81568627 0.87843137 0.86666667 0.87843137 0.81568627 0.8        0.83921569 0.81568627 0.81960784 0.78431373 0.62352941 0.96078431 0.75686275 0.80784314 0.8745098  1.         1.         0.86666667 0.91764706 0.86666667 0.82745098 0.8627451  0.90980392 0.96470588\n",
      "  0.        ]\n",
      " [0.01176471 0.79215686 0.89411765 0.87843137 0.86666667 0.82745098 0.82745098 0.83921569 0.80392157 0.80392157 0.80392157 0.8627451  0.94117647 0.31372549 0.58823529 1.         0.89803922 0.86666667 0.7372549  0.60392157 0.74901961 0.82352941 0.8        0.81960784 0.87058824 0.89411765 0.88235294\n",
      "  0.        ]\n",
      " [0.38431373 0.91372549 0.77647059 0.82352941 0.87058824 0.89803922 0.89803922 0.91764706 0.97647059 0.8627451  0.76078431 0.84313725 0.85098039 0.94509804 0.25490196 0.28627451 0.41568627 0.45882353 0.65882353 0.85882353 0.86666667 0.84313725 0.85098039 0.8745098  0.8745098  0.87843137 0.89803922\n",
      "  0.11372549]\n",
      " [0.29411765 0.8        0.83137255 0.8        0.75686275 0.80392157 0.82745098 0.88235294 0.84705882 0.7254902  0.77254902 0.80784314 0.77647059 0.83529412 0.94117647 0.76470588 0.89019608 0.96078431 0.9372549  0.8745098  0.85490196 0.83137255 0.81960784 0.87058824 0.8627451  0.86666667 0.90196078\n",
      "  0.2627451 ]\n",
      " [0.18823529 0.79607843 0.71764706 0.76078431 0.83529412 0.77254902 0.7254902  0.74509804 0.76078431 0.75294118 0.79215686 0.83921569 0.85882353 0.86666667 0.8627451  0.9254902  0.88235294 0.84705882 0.78039216 0.80784314 0.72941176 0.70980392 0.69411765 0.6745098  0.70980392 0.80392157 0.80784314\n",
      "  0.45098039]\n",
      " [0.         0.47843137 0.85882353 0.75686275 0.70196078 0.67058824 0.71764706 0.76862745 0.8        0.82352941 0.83529412 0.81176471 0.82745098 0.82352941 0.78431373 0.76862745 0.76078431 0.74901961 0.76470588 0.74901961 0.77647059 0.75294118 0.69019608 0.61176471 0.65490196 0.69411765 0.82352941\n",
      "  0.36078431]\n",
      " [0.         0.         0.29019608 0.74117647 0.83137255 0.74901961 0.68627451 0.6745098  0.68627451 0.70980392 0.7254902  0.7372549  0.74117647 0.7372549  0.75686275 0.77647059 0.8        0.81960784 0.82352941 0.82352941 0.82745098 0.7372549  0.7372549  0.76078431 0.75294118 0.84705882 0.66666667\n",
      "  0.        ]\n",
      " [0.00784314 0.         0.         0.         0.25882353 0.78431373 0.87058824 0.92941176 0.9372549  0.94901961 0.96470588 0.95294118 0.95686275 0.86666667 0.8627451  0.75686275 0.74901961 0.70196078 0.71372549 0.71372549 0.70980392 0.69019608 0.65098039 0.65882353 0.38823529 0.22745098 0.\n",
      "  0.        ]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.15686275 0.23921569 0.17254902 0.28235294 0.16078431 0.1372549  0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
      "  0.        ]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
      "  0.        ]\n",
      " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
      "  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(training_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tf.keras.models.Sequential([tf.keras.layers.Flatten(),tf.keras.layers.Dense(128,activation=tf.nn.relu),tf.keras.layers.Dense(10,activation=tf.nn.softmax)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.4996 - Accuracy: 0.8240\n",
      "Epoch 2/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3784 - Accuracy: 0.8619\n",
      "Epoch 3/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3374 - Accuracy: 0.8773\n",
      "Epoch 4/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3144 - Accuracy: 0.8847\n",
      "Epoch 5/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2970 - Accuracy: 0.8909\n",
      "Epoch 6/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2792 - Accuracy: 0.8954\n",
      "Epoch 7/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2686 - Accuracy: 0.9006\n",
      "Epoch 8/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2577 - Accuracy: 0.9034\n",
      "Epoch 9/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2492 - Accuracy: 0.9069\n",
      "Epoch 10/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2399 - Accuracy: 0.9101\n",
      "Epoch 11/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2314 - Accuracy: 0.9133\n",
      "Epoch 12/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2233 - Accuracy: 0.9147\n",
      "Epoch 13/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2167 - Accuracy: 0.9195\n",
      "Epoch 14/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2099 - Accuracy: 0.9208\n",
      "Epoch 15/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2037 - Accuracy: 0.9226\n",
      "Epoch 16/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1998 - Accuracy: 0.9252\n",
      "Epoch 17/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1924 - Accuracy: 0.9281\n",
      "Epoch 18/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1865 - Accuracy: 0.9305\n",
      "Epoch 19/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1836 - Accuracy: 0.9314\n",
      "Epoch 20/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1768 - Accuracy: 0.9342\n",
      "Epoch 21/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1740 - Accuracy: 0.9348\n",
      "Epoch 22/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1738 - Accuracy: 0.9335\n",
      "Epoch 23/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1658 - Accuracy: 0.9373\n",
      "Epoch 24/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1628 - Accuracy: 0.9387\n",
      "Epoch 25/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1595 - Accuracy: 0.9396\n",
      "Epoch 26/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1551 - Accuracy: 0.9423\n",
      "Epoch 27/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1502 - Accuracy: 0.9436\n",
      "Epoch 28/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1505 - Accuracy: 0.9426\n",
      "Epoch 29/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1446 - Accuracy: 0.9460\n",
      "Epoch 30/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1413 - Accuracy: 0.9469\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d0d9f0eaf0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=tf.optimizers.Adam(),loss='sparse_categorical_crossentropy',metrics=['Accuracy'])\n",
    "model.fit(training_images, training_labels, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 2ms/step - loss: 0.4272 - Accuracy: 0.8824\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.42718568444252014, 0.8823999762535095]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
